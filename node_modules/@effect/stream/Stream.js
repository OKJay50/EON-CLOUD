"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.flatMapParBuffer = exports.flatMapPar = exports.flatMap = exports.findEffect = exports.find = exports.finalizer = exports.filterEffect = exports.filter = exports.failSync = exports.failCauseSync = exports.failCause = exports.fail = exports.execute = exports.ensuring = exports.empty = exports.either = exports.dropWhileEffect = exports.dropWhile = exports.dropUntilEffect = exports.dropUntil = exports.dropRight = exports.drop = exports.drainFork = exports.drain = exports.done = exports.distributedWithDynamic = exports.distributedWith = exports.dieSync = exports.dieMessage = exports.die = exports.debounce = exports.crossWith = exports.crossRight = exports.crossLeft = exports.cross = exports.contramapContext = exports.contextWithStream = exports.contextWithEffect = exports.contextWith = exports.context = exports.concatAll = exports.concat = exports.combineChunks = exports.combine = exports.collectWhileSuccess = exports.collectWhileSome = exports.collectWhileRight = exports.collectWhileLeft = exports.collectWhileEffect = exports.collectWhile = exports.collectSuccess = exports.collectSome = exports.collectRight = exports.collectLeft = exports.collectEffect = exports.collect = exports.chunksWith = exports.chunks = exports.changesWithEffect = exports.changesWith = exports.changes = exports.catchSomeCause = exports.catchSome = exports.catchAllCause = exports.catchAll = exports.bufferUnbounded = exports.bufferSliding = exports.bufferDropping = exports.bufferChunksSliding = exports.bufferChunksDropping = exports.bufferChunks = exports.buffer = exports.broadcastedQueuesDynamic = exports.broadcastedQueues = exports.broadcastDynamic = exports.broadcast = exports.branchAfter = exports.bindDiscard = exports.bind = exports.asyncScoped = exports.asyncOption = exports.asyncInterrupt = exports.asyncEffect = exports.async = exports.as = exports.aggregateWithinEither = exports.aggregateWithin = exports.aggregate = exports.acquireRelease = exports.absolve = exports.StreamTypeId = exports.Pointed = exports.Monad = exports.Invariant = exports.FlatMap = exports.Do = exports.DefaultChunkSize = exports.Covariant = exports.Chainable = exports.Bicovariant = void 0;
exports.mergeAllUnbounded = exports.mergeAll = exports.merge = exports.mapErrorCause = exports.mapError = exports.mapEffectParUnordered = exports.mapEffectParByKeyBuffer = exports.mapEffectParByKey = exports.mapEffectPar = exports.mapEffect = exports.mapConcatEffect = exports.mapConcatChunkEffect = exports.mapConcatChunk = exports.mapConcat = exports.mapChunksEffect = exports.mapChunks = exports.mapBoth = exports.mapAccumEffect = exports.mapAccum = exports.map = exports.make = exports.logWarningCauseMessage = exports.logWarningCause = exports.logWarning = exports.logTraceCauseMessage = exports.logTraceCause = exports.logTrace = exports.logInfoCauseMessage = exports.logInfoCause = exports.logInfo = exports.logFatalCauseMessage = exports.logFatalCause = exports.logFatal = exports.logErrorCauseMessage = exports.logErrorCause = exports.logError = exports.logDebugCauseMessage = exports.logDebugCause = exports.logDebug = exports.log = exports.letDiscard = exports.let = exports.iterate = exports.intersperseAffixes = exports.intersperse = exports.interruptWhenDeferred = exports.interruptWhen = exports.interruptAfter = exports.interleaveWith = exports.interleave = exports.identity = exports.haltWhenDeferred = exports.haltWhen = exports.haltAfter = exports.groupedWithin = exports.grouped = exports.groupByKeyBuffer = exports.groupByKey = exports.groupByBuffer = exports.groupBy = exports.groupAdjacentBy = exports.fromSchedule = exports.fromQueueWithShutdown = exports.fromQueue = exports.fromPull = exports.fromIteratorSucceed = exports.fromIterableEffect = exports.fromIterable = exports.fromHubWithShutdown = exports.fromHubScopedWithShutdown = exports.fromHubScoped = exports.fromHub = exports.fromEffectOption = exports.fromEffect = exports.fromChunks = exports.fromChunkQueueWithShutdown = exports.fromChunkQueue = exports.fromChunkHubWithShutdown = exports.fromChunkHubScopedWithShutdown = exports.fromChunkHubScoped = exports.fromChunkHub = exports.fromChunk = exports.fromChannel = exports.fromAsyncIterable = exports.forever = exports.flattenTake = exports.flattenParUnboundedBuffer = exports.flattenParUnbounded = exports.flattenParBuffer = exports.flattenPar = exports.flattenIterables = exports.flattenExitOption = exports.flattenExit = exports.flattenEffectParUnordered = exports.flattenEffectPar = exports.flattenEffect = exports.flattenChunks = exports.flatten = exports.flatMapParSwitchBuffer = exports.flatMapParSwitch = void 0;
exports.someOrElse = exports.some = exports.slidingSize = exports.sliding = exports.scoped = exports.scheduleWith = exports.scheduleEither = exports.schedule = exports.scanReduceEffect = exports.scanReduce = exports.scanEffect = exports.scan = exports.runSum = exports.runScoped = exports.runLast = exports.runIntoQueueScoped = exports.runIntoQueueElementsScoped = exports.runIntoQueue = exports.runIntoHubScoped = exports.runIntoHub = exports.runHead = exports.runForEachWhileScoped = exports.runForEachWhile = exports.runForEachScoped = exports.runForEachChunkScoped = exports.runForEachChunk = exports.runForEach = exports.runFoldWhileScopedEffect = exports.runFoldWhileScoped = exports.runFoldWhileEffect = exports.runFoldWhile = exports.runFoldScopedEffect = exports.runFoldScoped = exports.runFoldEffect = exports.runFold = exports.runDrain = exports.runCount = exports.runCollect = exports.run = exports.rightOrFail = exports.right = exports.retry = exports.repeatWith = exports.repeatValue = exports.repeatElementsWith = exports.repeatElementsEither = exports.repeatElements = exports.repeatEither = exports.repeatEffectWithSchedule = exports.repeatEffectOption = exports.repeatEffectChunkOption = exports.repeatEffectChunk = exports.repeatEffect = exports.repeat = exports.refineOrDieWith = exports.refineOrDie = exports.rechunk = exports.range = exports.provideSomeLayer = exports.provideServiceStream = exports.provideServiceEffect = exports.provideService = exports.provideLayer = exports.provideContext = exports.prepend = exports.pipeThroughChannelOrFail = exports.pipeThroughChannel = exports.pipeThrough = exports.peel = exports.partitionEitherBuffer = exports.partitionEither = exports.partitionBuffer = exports.partition = exports.paginateEffect = exports.paginateChunkEffect = exports.paginateChunk = exports.paginate = exports.orElseSucceed = exports.orElseOptional = exports.orElseIfEmptyStream = exports.orElseIfEmptyChunk = exports.orElseIfEmpty = exports.orElseFail = exports.orElseEither = exports.orElse = exports.orDieWith = exports.orDie = exports.onError = exports.onDone = exports.never = exports.mkString = exports.mergeWithHaltStrategy = exports.mergeWith = exports.mergeRight = exports.mergeLeft = exports.mergeHaltStrategy = exports.mergeHaltRight = exports.mergeHaltLeft = exports.mergeHaltEither = exports.mergeEither = void 0;
exports.zipWithPreviousAndNext = exports.zipWithPrevious = exports.zipWithNext = exports.zipWithIndex = exports.zipWithChunks = exports.zipWith = exports.zipRight = exports.zipLeft = exports.zipLatestWith = exports.zipLatest = exports.zipFlatten = exports.zipAllWith = exports.zipAllSortedByKeyWith = exports.zipAllSortedByKeyRight = exports.zipAllSortedByKeyLeft = exports.zipAllSortedByKey = exports.zipAllRight = exports.zipAllLeft = exports.zipAll = exports.zip = exports.whenEffect = exports.whenCaseEffect = exports.whenCase = exports.when = exports.updateService = exports.unwrapScoped = exports.unwrap = exports.unit = exports.unfoldEffect = exports.unfoldChunkEffect = exports.unfoldChunk = exports.unfold = exports.transduce = exports.toQueueUnbounded = exports.toQueueSlidingCapacity = exports.toQueueSliding = exports.toQueueOfElementsCapacity = exports.toQueueOfElements = exports.toQueueDroppingCapacity = exports.toQueueDropping = exports.toQueueCapacity = exports.toQueue = exports.toPull = exports.toHub = exports.toChannel = exports.timeoutTo = exports.timeoutFailCause = exports.timeoutFail = exports.timeout = exports.tick = exports.throttleShapeEffectBurst = exports.throttleShapeEffect = exports.throttleShapeBurst = exports.throttleShape = exports.throttleEnforceEffectBurst = exports.throttleEnforceEffect = exports.throttleEnforceBurst = exports.throttleEnforce = exports.tapSink = exports.tapErrorCause = exports.tapError = exports.tap = exports.takeWhile = exports.takeUntilEffect = exports.takeUntil = exports.takeRight = exports.take = exports.sync = exports.suspend = exports.succeed = exports.splitOnChunk = exports.split = exports.someOrFail = void 0;
var _Function = /*#__PURE__*/require("@effect/data/Function");
var chainable = /*#__PURE__*/_interopRequireWildcard( /*#__PURE__*/require("@effect/data/typeclass/Chainable"));
var covariant = /*#__PURE__*/_interopRequireWildcard( /*#__PURE__*/require("@effect/data/typeclass/Covariant"));
var of_ = /*#__PURE__*/_interopRequireWildcard( /*#__PURE__*/require("@effect/data/typeclass/Of"));
var _groupBy = /*#__PURE__*/_interopRequireWildcard( /*#__PURE__*/require("@effect/stream/internal/groupBy"));
var internal = /*#__PURE__*/_interopRequireWildcard( /*#__PURE__*/require("@effect/stream/internal/stream"));
function _getRequireWildcardCache(nodeInterop) { if (typeof WeakMap !== "function") return null; var cacheBabelInterop = new WeakMap(); var cacheNodeInterop = new WeakMap(); return (_getRequireWildcardCache = function (nodeInterop) { return nodeInterop ? cacheNodeInterop : cacheBabelInterop; })(nodeInterop); }
function _interopRequireWildcard(obj, nodeInterop) { if (!nodeInterop && obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== "object" && typeof obj !== "function") { return { default: obj }; } var cache = _getRequireWildcardCache(nodeInterop); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (key !== "default" && Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }
/**
 * @since 1.0.0
 * @category symbols
 */
const StreamTypeId = internal.StreamTypeId;
/**
 * The default chunk size used by the various combinators and constructors of
 * `Stream`.
 *
 * @since 1.0.0
 * @category constants
 */
exports.StreamTypeId = StreamTypeId;
const DefaultChunkSize = internal.DefaultChunkSize;
/**
 * Submerges the error case of an `Either` into the `Stream`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.DefaultChunkSize = DefaultChunkSize;
const absolve = internal.absolve;
/**
 * Creates a stream from a single value that will get cleaned up after the
 * stream is consumed.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.absolve = absolve;
const acquireRelease = internal.acquireRelease;
/**
 * Aggregates elements of this stream using the provided sink for as long as
 * the downstream operators on the stream are busy.
 *
 * This operator divides the stream into two asynchronous "islands". Operators
 * upstream of this operator run on one fiber, while downstream operators run
 * on another. Whenever the downstream fiber is busy processing elements, the
 * upstream fiber will feed elements into the sink until it signals
 * completion.
 *
 * Any sink can be used here, but see `Sink.foldWeightedEffect` and
 * `Sink.foldUntilEffect` for sinks that cover the common usecases.
 *
 * @since 1.0.0
 * @category utils
 */
exports.acquireRelease = acquireRelease;
const aggregate = internal.aggregate;
/**
 * Like `aggregateWithinEither`, but only returns the `Right` results.
 *
 * @param sink A `Sink` used to perform the aggregation.
 * @param schedule A `Schedule` used to signal when to stop the aggregation.
 * @since 1.0.0
 * @category utils
 */
exports.aggregate = aggregate;
const aggregateWithin = internal.aggregateWithin;
/**
 * Aggregates elements using the provided sink until it completes, or until
 * the delay signalled by the schedule has passed.
 *
 * This operator divides the stream into two asynchronous islands. Operators
 * upstream of this operator run on one fiber, while downstream operators run
 * on another. Elements will be aggregated by the sink until the downstream
 * fiber pulls the aggregated value, or until the schedule's delay has passed.
 *
 * Aggregated elements will be fed into the schedule to determine the delays
 * between pulls.
 *
 * @param sink A `Sink` used to perform the aggregation.
 * @param schedule A `Schedule` used to signal when to stop the aggregation.
 * @since 1.0.0
 * @category utils
 */
exports.aggregateWithin = aggregateWithin;
const aggregateWithinEither = internal.aggregateWithinEither;
/**
 * Maps the success values of this stream to the specified constant value.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.aggregateWithinEither = aggregateWithinEither;
const as = internal.as;
exports.as = as;
const _async = internal._async;
exports.async = _async;
/**
 * Creates a stream from an asynchronous callback that can be called multiple
 * times The registration of the callback itself returns an effect. The
 * optionality of the error type `E` can be used to signal the end of the
 * stream, by setting it to `None`.
 *
 * @since 1.0.0
 * @category constructors
 */
const asyncEffect = internal.asyncEffect;
/**
 * Creates a stream from an asynchronous callback that can be called multiple
 * times. The registration of the callback returns either a canceler or
 * synchronously returns a stream. The optionality of the error type `E` can
 * be used to signal the end of the stream, by setting it to `None`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.asyncEffect = asyncEffect;
const asyncInterrupt = internal.asyncInterrupt;
/**
 * Creates a stream from an asynchronous callback that can be called multiple
 * times. The registration of the callback can possibly return the stream
 * synchronously. The optionality of the error type `E` can be used to signal
 * the end of the stream, by setting it to `None`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.asyncInterrupt = asyncInterrupt;
const asyncOption = internal.asyncOption;
/**
 * Creates a stream from an asynchronous callback that can be called multiple
 * times. The registration of the callback itself returns an a scoped
 * resource. The optionality of the error type `E` can be used to signal the
 * end of the stream, by setting it to `None`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.asyncOption = asyncOption;
const asyncScoped = internal.asyncScoped;
/**
 * Returns a `Stream` that first collects `n` elements from the input `Stream`,
 * and then creates a new `Stream` using the specified function, and sends all
 * the following elements through that.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.asyncScoped = asyncScoped;
const branchAfter = internal.branchAfter;
/**
 * Fan out the stream, producing a list of streams that have the same elements
 * as this stream. The driver stream will only ever advance the `maximumLag`
 * chunks before the slowest downstream stream.
 *
 * @macro traced
 * @since 1.0.0
 * @category utils
 */
exports.branchAfter = branchAfter;
const broadcast = internal.broadcast;
/**
 * Fan out the stream, producing a dynamic number of streams that have the
 * same elements as this stream. The driver stream will only ever advance the
 * `maximumLag` chunks before the slowest downstream stream.
 *
 * @macro traced
 * @since 1.0.0
 * @category utils
 */
exports.broadcast = broadcast;
const broadcastDynamic = internal.broadcastDynamic;
/**
 * Converts the stream to a scoped list of queues. Every value will be
 * replicated to every queue with the slowest queue being allowed to buffer
 * `maximumLag` chunks before the driver is back pressured.
 *
 * Queues can unsubscribe from upstream by shutting down.
 *
 * @macro traced
 * @since 1.0.0
 * @category utils
 */
exports.broadcastDynamic = broadcastDynamic;
const broadcastedQueues = internal.broadcastedQueues;
/**
 * Converts the stream to a scoped dynamic amount of queues. Every chunk will
 * be replicated to every queue with the slowest queue being allowed to buffer
 * `maximumLag` chunks before the driver is back pressured.
 *
 * Queues can unsubscribe from upstream by shutting down.
 *
 * @macro traced
 * @since 1.0.0
 * @category utils
 */
exports.broadcastedQueues = broadcastedQueues;
const broadcastedQueuesDynamic = internal.broadcastedQueuesDynamic;
/**
 * Allows a faster producer to progress independently of a slower consumer by
 * buffering up to `capacity` elements in a queue.
 *
 * @note This combinator destroys the chunking structure. It's recommended to
 *       use rechunk afterwards. Additionally, prefer capacities that are powers
 *       of 2 for better performance.
 * @since 1.0.0
 * @category utils
 */
exports.broadcastedQueuesDynamic = broadcastedQueuesDynamic;
const buffer = internal.buffer;
/**
 * Allows a faster producer to progress independently of a slower consumer by
 * buffering up to `capacity` chunks in a queue.
 *
 * @note Prefer capacities that are powers of 2 for better performance.
 * @since 1.0.0
 * @category utils
 */
exports.buffer = buffer;
const bufferChunks = internal.bufferChunks;
/**
 * Allows a faster producer to progress independently of a slower consumer by
 * buffering up to `capacity` chunks in a dropping queue.
 *
 * @note Prefer capacities that are powers of 2 for better performance.
 * @since 1.0.0
 * @category utils
 */
exports.bufferChunks = bufferChunks;
const bufferChunksDropping = internal.bufferChunksDropping;
/**
 * Allows a faster producer to progress independently of a slower consumer by
 * buffering up to `capacity` chunks in a sliding queue.
 *
 * @note Prefer capacities that are powers of 2 for better performance.
 * @since 1.0.0
 * @category utils
 */
exports.bufferChunksDropping = bufferChunksDropping;
const bufferChunksSliding = internal.bufferChunksSliding;
/**
 * Allows a faster producer to progress independently of a slower consumer by
 * buffering up to `capacity` elements in a dropping queue.
 *
 * @note This combinator destroys the chunking structure. It's recommended to
 *       use rechunk afterwards. Additionally, Prefer capacities that are
 *       powers of 2 for better performance.
 * @since 1.0.0
 * @category utils
 */
exports.bufferChunksSliding = bufferChunksSliding;
const bufferDropping = internal.bufferDropping;
/**
 * Allows a faster producer to progress independently of a slower consumer by
 * buffering up to `capacity` elements in a sliding queue.
 *
 * @note This combinator destroys the chunking structure. It's recommended to
 *       use rechunk afterwards. Additionally, Prefer capacities that are
 *       powers of 2 for better performance.
 * @since 1.0.0
 * @category utils
 */
exports.bufferDropping = bufferDropping;
const bufferSliding = internal.bufferSliding;
/**
 * Allows a faster producer to progress independently of a slower consumer by
 * buffering chunks into an unbounded queue.
 *
 * @since 1.0.0
 * @category utils
 */
exports.bufferSliding = bufferSliding;
const bufferUnbounded = internal.bufferUnbounded;
/**
 * Switches over to the stream produced by the provided function in case this
 * one fails with a typed error.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.bufferUnbounded = bufferUnbounded;
const catchAll = internal.catchAll;
/**
 * Switches over to the stream produced by the provided function in case this
 * one fails. Allows recovery from all causes of failure, including
 * interruption if the stream is uninterruptible.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.catchAll = catchAll;
const catchAllCause = internal.catchAllCause;
/**
 * Switches over to the stream produced by the provided function in case this
 * one fails with some typed error.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.catchAllCause = catchAllCause;
const catchSome = internal.catchSome;
/**
 * Switches over to the stream produced by the provided function in case this
 * one fails with some errors. Allows recovery from all causes of failure,
 * including interruption if the stream is uninterruptible.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.catchSome = catchSome;
const catchSomeCause = internal.catchSomeCause;
/**
 * Returns a new stream that only emits elements that are not equal to the
 * previous element emitted, using natural equality to determine whether two
 * elements are equal.
 *
 * @since 1.0.0
 * @category utils
 */
exports.catchSomeCause = catchSomeCause;
const changes = internal.changes;
/**
 * Returns a new stream that only emits elements that are not equal to the
 * previous element emitted, using the specified function to determine whether
 * two elements are equal.
 *
 * @since 1.0.0
 * @category utils
 */
exports.changes = changes;
const changesWith = internal.changesWith;
/**
 * Returns a new stream that only emits elements that are not equal to the
 * previous element emitted, using the specified effectual function to
 * determine whether two elements are equal.
 *
 * @since 1.0.0
 * @category utils
 */
exports.changesWith = changesWith;
const changesWithEffect = internal.changesWithEffect;
/**
 * Exposes the underlying chunks of the stream as a stream of chunks of
 * elements.
 *
 * @since 1.0.0
 * @category utils
 */
exports.changesWithEffect = changesWithEffect;
const chunks = internal.chunks;
/**
 * Performs the specified stream transformation with the chunk structure of
 * the stream exposed.
 *
 * @since 1.0.0
 * @category utils
 */
exports.chunks = chunks;
const chunksWith = internal.chunksWith;
/**
 * Performs a filter and map in a single step.
 *
 * @since 1.0.0
 * @category utils
 */
exports.chunksWith = chunksWith;
const collect = internal.collect;
/**
 * Performs an effectful filter and map in a single step.
 *
 * @since 1.0.0
 * @category utils
 */
exports.collect = collect;
const collectEffect = internal.collectEffect;
/**
 * Filters any `Right` values.
 *
 * @since 1.0.0
 * @category utils
 */
exports.collectEffect = collectEffect;
const collectLeft = internal.collectLeft;
/**
 * Filters any `Left` values.
 *
 * @since 1.0.0
 * @category utils
 */
exports.collectLeft = collectLeft;
const collectRight = internal.collectRight;
/**
 * Filters any 'None' values.
 *
 * @since 1.0.0
 * @category utils
 */
exports.collectRight = collectRight;
const collectSome = internal.collectSome;
/**
 * Filters any `Exit.Failure` values.
 *
 * @since 1.0.0
 * @category utils
 */
exports.collectSome = collectSome;
const collectSuccess = internal.collectSuccess;
/**
 * Transforms all elements of the stream for as long as the specified partial
 * function is defined.
 *
 * @since 1.0.0
 * @category utils
 */
exports.collectSuccess = collectSuccess;
const collectWhile = internal.collectWhile;
/**
 * Terminates the stream when encountering the first `Right`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.collectWhile = collectWhile;
const collectWhileLeft = internal.collectWhileLeft;
/**
 * Terminates the stream when encountering the first `None`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.collectWhileLeft = collectWhileLeft;
const collectWhileSome = internal.collectWhileSome;
/**
 * Terminates the stream when encountering the first `Left`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.collectWhileSome = collectWhileSome;
const collectWhileRight = internal.collectWhileRight;
/**
 * Terminates the stream when encountering the first `Exit.Failure`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.collectWhileRight = collectWhileRight;
const collectWhileSuccess = internal.collectWhileSuccess;
/**
 * Effectfully transforms all elements of the stream for as long as the
 * specified partial function is defined.
 *
 * @since 1.0.0
 * @category utils
 */
exports.collectWhileSuccess = collectWhileSuccess;
const collectWhileEffect = internal.collectWhileEffect;
/**
 * Combines the elements from this stream and the specified stream by
 * repeatedly applying the function `f` to extract an element using both sides
 * and conceptually "offer" it to the destination stream. `f` can maintain
 * some internal state to control the combining process, with the initial
 * state being specified by `s`.
 *
 * Where possible, prefer `Stream.combineChunks` for a more efficient
 * implementation.
 *
 * @since 1.0.0
 * @category utils
 */
exports.collectWhileEffect = collectWhileEffect;
const combine = internal.combine;
/**
 * Combines the chunks from this stream and the specified stream by repeatedly
 * applying the function `f` to extract a chunk using both sides and
 * conceptually "offer" it to the destination stream. `f` can maintain some
 * internal state to control the combining process, with the initial state
 * being specified by `s`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.combine = combine;
const combineChunks = internal.combineChunks;
/**
 * Concatenates the specified stream with this stream, resulting in a stream
 * that emits the elements from this stream and then the elements from the
 * specified stream.
 *
 * @since 1.0.0
 * @category utils
 */
exports.combineChunks = combineChunks;
const concat = internal.concat;
/**
 * Concatenates all of the streams in the chunk to one stream.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.concat = concat;
const concatAll = internal.concatAll;
/**
 * Composes this stream with the specified stream to create a cartesian
 * product of elements. The `that` stream would be run multiple times, for
 * every element in the `this` stream.
 *
 * See also `Stream.zip` for the more common point-wise variant.
 *
 * @since 1.0.0
 * @category utils
 */
exports.concatAll = concatAll;
const cross = internal.cross;
/**
 * Composes this stream with the specified stream to create a cartesian
 * product of elements, but keeps only elements from this stream. The `that`
 * stream would be run multiple times, for every element in the `this` stream.
 *
 * See also `Stream.zipLeft` for the more common point-wise variant.
 *
 * @since 1.0.0
 * @category utils
 */
exports.cross = cross;
const crossLeft = internal.crossLeft;
/**
 * Composes this stream with the specified stream to create a cartesian
 * product of elements, but keeps only elements from the other stream. The
 * `that` stream would be run multiple times, for every element in the `this`
 * stream.
 *
 * See also `Stream.zipRight` for the more common point-wise variant.
 *
 * @since 1.0.0
 * @category utils
 */
exports.crossLeft = crossLeft;
const crossRight = internal.crossRight;
/**
 * Composes this stream with the specified stream to create a cartesian
 * product of elements with a specified function. The `that` stream would be
 * run multiple times, for every element in the `this` stream.
 *
 * See also `Stream.zipWith` for the more common point-wise variant.
 *
 * @since 1.0.0
 * @category utils
 */
exports.crossRight = crossRight;
const crossWith = internal.crossWith;
/**
 * Delays the emission of values by holding new values for a set duration. If
 * no new values arrive during that time the value is emitted, however if a
 * new value is received during the holding period the previous value is
 * discarded and the process is repeated with the new value.
 *
 * This operator is useful if you have a stream of "bursty" events which
 * eventually settle down and you only need the final event of the burst. For
 * example, a search engine may only want to initiate a search after a user
 * has paused typing so as to not prematurely recommend results.
 *
 * @since 1.0.0
 * @category utils
 */
exports.crossWith = crossWith;
const debounce = internal.debounce;
/**
 * The stream that dies with the specified defect.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.debounce = debounce;
const die = internal.die;
/**
 * The stream that dies with the specified lazily evaluated defect.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.die = die;
const dieSync = internal.dieSync;
/**
 * The stream that dies with an exception described by `message`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.dieSync = dieSync;
const dieMessage = internal.dieMessage;
/**
 * More powerful version of `Stream.broadcast`. Allows to provide a function
 * that determines what queues should receive which elements. The decide
 * function will receive the indices of the queues in the resulting list.
 *
 * @since 1.0.0
 * @category utils
 */
exports.dieMessage = dieMessage;
const distributedWith = internal.distributedWith;
/**
 * More powerful version of `Stream.distributedWith`. This returns a function
 * that will produce new queues and corresponding indices. You can also
 * provide a function that will be executed after the final events are
 * enqueued in all queues. Shutdown of the queues is handled by the driver.
 * Downstream users can also shutdown queues manually. In this case the driver
 * will continue but no longer backpressure on them.
 *
 * @macro traced
 * @since 1.0.0
 * @category utils
 */
exports.distributedWith = distributedWith;
const distributedWithDynamic = internal.distributedWithDynamic;
/**
 * The stream that ends with the specified `Exit` value.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.distributedWithDynamic = distributedWithDynamic;
const done = internal.done;
/**
 * Converts this stream to a stream that executes its effects but emits no
 * elements. Useful for sequencing effects using streams:
 *
 * @since 1.0.0
 * @category utils
 */
exports.done = done;
const drain = internal.drain;
/**
 * Drains the provided stream in the background for as long as this stream is
 * running. If this stream ends before `other`, `other` will be interrupted.
 * If `other` fails, this stream will fail with that error.
 *
 * @since 1.0.0
 * @category utils
 */
exports.drain = drain;
const drainFork = internal.drainFork;
/**
 * Drops the specified number of elements from this stream.
 *
 * @since 1.0.0
 * @category utils
 */
exports.drainFork = drainFork;
const drop = internal.drop;
/**
 * Drops the last specified number of elements from this stream.
 *
 * @note This combinator keeps `n` elements in memory. Be careful with big
 *       numbers.
 * @since 1.0.0
 * @category utils
 */
exports.drop = drop;
const dropRight = internal.dropRight;
/**
 * Drops all elements of the stream until the specified predicate evaluates to
 * `true`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.dropRight = dropRight;
const dropUntil = internal.dropUntil;
/**
 * Drops all elements of the stream until the specified effectful predicate
 * evaluates to `true`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.dropUntil = dropUntil;
const dropUntilEffect = internal.dropUntilEffect;
/**
 * Drops all elements of the stream for as long as the specified predicate
 * evaluates to `true`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.dropUntilEffect = dropUntilEffect;
const dropWhile = internal.dropWhile;
/**
 * Drops all elements of the stream for as long as the specified predicate
 * produces an effect that evalutates to `true`
 *
 * @since 1.0.0
 * @category utils
 */
exports.dropWhile = dropWhile;
const dropWhileEffect = internal.dropWhileEffect;
/**
 * Returns a stream whose failures and successes have been lifted into an
 * `Either`. The resulting stream cannot fail, because the failures have been
 * exposed as part of the `Either` success case.
 *
 * @note The stream will end as soon as the first error occurs.
 *
 * @since 1.0.0
 * @category utils
 */
exports.dropWhileEffect = dropWhileEffect;
const either = internal.either;
/**
 * The empty stream.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.either = either;
const empty = internal.empty;
/**
 * Executes the provided finalizer after this stream's finalizers run.
 *
 * @since 1.0.0
 * @category utils
 */
exports.empty = empty;
const ensuring = internal.ensuring;
/**
 * Accesses the whole context of the stream.
 *
 * @since 1.0.0
 * @category context
 */
exports.ensuring = ensuring;
const context = internal.context;
/**
 * Accesses the context of the stream.
 *
 * @since 1.0.0
 * @category context
 */
exports.context = context;
const contextWith = internal.contextWith;
/**
 * Accesses the context of the stream in the context of an effect.
 *
 * @since 1.0.0
 * @category context
 */
exports.contextWith = contextWith;
const contextWithEffect = internal.contextWithEffect;
/**
 * Accesses the context of the stream in the context of a stream.
 *
 * @since 1.0.0
 * @category context
 */
exports.contextWithEffect = contextWithEffect;
const contextWithStream = internal.contextWithStream;
/**
 * Creates a stream that executes the specified effect but emits no elements.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.contextWithStream = contextWithStream;
const execute = internal.execute;
/**
 * Terminates with the specified error.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.execute = execute;
const fail = internal.fail;
/**
 * Terminates with the specified lazily evaluated error.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fail = fail;
const failSync = internal.failSync;
/**
 * The stream that always fails with the specified `Cause`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.failSync = failSync;
const failCause = internal.failCause;
/**
 * The stream that always fails with the specified lazily evaluated `Cause`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.failCause = failCause;
const failCauseSync = internal.failCauseSync;
/**
 * Filters the elements emitted by this stream using the provided function.
 *
 * @since 1.0.0
 * @category filtering
 */
exports.failCauseSync = failCauseSync;
const filter = internal.filter;
/**
 * Effectfully filters the elements emitted by this stream.
 *
 * @since 1.0.0
 * @category filtering
 */
exports.filter = filter;
const filterEffect = internal.filterEffect;
/**
 * Creates a one-element stream that never fails and executes the finalizer
 * when it ends.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.filterEffect = filterEffect;
const finalizer = internal.finalizer;
/**
 * Finds the first element emitted by this stream that satisfies the provided
 * predicate.
 *
 * @since 1.0.0
 * @category elements
 */
exports.finalizer = finalizer;
const find = internal.find;
/**
 * Finds the first element emitted by this stream that satisfies the provided
 * effectful predicate.
 *
 * @since 1.0.0
 * @category elements
 */
exports.find = find;
const findEffect = internal.findEffect;
/**
 * Returns a stream made of the concatenation in strict order of all the
 * streams produced by passing each element of this stream to `f0`
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.findEffect = findEffect;
const flatMap = internal.flatMap;
/**
 * Maps each element of this stream to another stream and returns the
 * non-deterministic merge of those streams, executing up to `n` inner streams
 * concurrently. Up to `bufferSize` elements of the produced streams may be
 * buffered in memory by this operator.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flatMap = flatMap;
const flatMapPar = internal.flatMapPar;
/**
 * Like `flatMapPar`, but with a configurable `bufferSize` parameter.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flatMapPar = flatMapPar;
const flatMapParBuffer = internal.flatMapParBuffer;
/**
 * Maps each element of this stream to another stream and returns the
 * non-deterministic merge of those streams, executing up to `n` inner streams
 * concurrently. When a new stream is created from an element of the source
 * stream, the oldest executing stream is cancelled. Up to `bufferSize`
 * elements of the produced streams may be buffered in memory by this
 * operator.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flatMapParBuffer = flatMapParBuffer;
const flatMapParSwitch = internal.flatMapParSwitch;
/**
 * Like `flatMapParSwitch`, but with a configurable `bufferSize` parameter.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flatMapParSwitch = flatMapParSwitch;
const flatMapParSwitchBuffer = internal.flatMapParSwitchBuffer;
/**
 * Flattens this stream-of-streams into a stream made of the concatenation in
 * strict order of all the streams.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flatMapParSwitchBuffer = flatMapParSwitchBuffer;
const flatten = internal.flatten;
/**
 * Submerges the chunks carried by this stream into the stream's structure,
 * while still preserving them.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flatten = flatten;
const flattenChunks = internal.flattenChunks;
/**
 * Flattens `Effect` values into the stream's structure, preserving all
 * information about the effect.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flattenChunks = flattenChunks;
const flattenEffect = internal.flattenEffect;
/**
 * Flattens `Effect` values into the stream's structure, preserving all
 * information about the effect.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flattenEffect = flattenEffect;
const flattenEffectPar = internal.flattenEffectPar;
/**
 * Flattens `Effect` values into the stream's structure, preserving all
 * information about the effect. The element order is
 * not enforced by this combinator, and elements may be reordered.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flattenEffectPar = flattenEffectPar;
const flattenEffectParUnordered = internal.flattenEffectParUnordered;
/**
 * Flattens `Exit` values. `Exit.Failure` values translate to stream
 * failures while `Exit.Success` values translate to stream elements.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flattenEffectParUnordered = flattenEffectParUnordered;
const flattenExit = internal.flattenExit;
/**
 * Unwraps `Exit` values that also signify end-of-stream by failing with `None`.
 *
 * For `Exit` values that do not signal end-of-stream, prefer:
 *
 * ```ts
 * stream.mapZIO(ZIO.done(_))
 * ```
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flattenExit = flattenExit;
const flattenExitOption = internal.flattenExitOption;
/**
 * Submerges the iterables carried by this stream into the stream's structure,
 * while still preserving them.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flattenExitOption = flattenExitOption;
const flattenIterables = internal.flattenIterables;
/**
 * Flattens a stream of streams into a stream by executing a non-deterministic
 * concurrent merge. Up to `n` streams may be consumed in parallel and up to
 * `outputBuffer` elements may be buffered by this operator.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flattenIterables = flattenIterables;
const flattenPar = internal.flattenPar;
/**
 * Like `flattenPar`, but with a configurable `bufferSize` parameter.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flattenPar = flattenPar;
const flattenParBuffer = internal.flattenParBuffer;
/**
 * Like `Stream.flattenPar`, but executes all streams concurrently.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flattenParBuffer = flattenParBuffer;
const flattenParUnbounded = internal.flattenParUnbounded;
/**
 * Like `Stream.flattenParUnbounded`, but with `bufferSize` parameter.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flattenParUnbounded = flattenParUnbounded;
const flattenParUnboundedBuffer = internal.flattenParUnboundedBuffer;
/**
 * Unwraps `Exit` values and flatten chunks that also signify end-of-stream
 * by failing with `None`.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.flattenParUnboundedBuffer = flattenParUnboundedBuffer;
const flattenTake = internal.flattenTake;
/**
 * Repeats this stream forever.
 *
 * @since 1.0.0
 * @category utils
 */
exports.flattenTake = flattenTake;
const forever = internal.forever;
/**
 * Creates a stream from an `AsyncIterable`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.forever = forever;
const fromAsyncIterable = internal.fromAsyncIterable;
/**
 * Creates a stream from a `Channel`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromAsyncIterable = fromAsyncIterable;
const fromChannel = internal.fromChannel;
/**
 * Creates a channel from a `Stream`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromChannel = fromChannel;
const toChannel = internal.toChannel;
/**
 * Creates a stream from a `Chunk` of values.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.toChannel = toChannel;
const fromChunk = internal.fromChunk;
/**
 * Creates a stream from a subscription to a `Hub`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromChunk = fromChunk;
const fromChunkHub = internal.fromChunkHub;
/**
 * Creates a stream from a subscription to a `Hub` in the context of a scoped
 * effect. The scoped effect describes subscribing to receive messages from
 * the hub while the stream describes taking messages from the hub.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromChunkHub = fromChunkHub;
const fromChunkHubScoped = internal.fromChunkHubScoped;
/**
 * Creates a stream from a subscription to a `Hub`.
 *
 * The hub will be shut down once the stream is closed.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromChunkHubScoped = fromChunkHubScoped;
const fromChunkHubWithShutdown = internal.fromChunkHubWithShutdown;
/**
 * Creates a stream from a subscription to a `Hub` in the context of a scoped
 * effect. The scoped effect describes subscribing to receive messages from
 * the hub while the stream describes taking messages from the hub.
 *
 * The hub will be shut down once the stream is closed.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromChunkHubWithShutdown = fromChunkHubWithShutdown;
const fromChunkHubScopedWithShutdown = internal.fromChunkHubScopedWithShutdown;
/**
 * Creates a stream from a `Queue` of values.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromChunkHubScopedWithShutdown = fromChunkHubScopedWithShutdown;
const fromChunkQueue = internal.fromChunkQueue;
/**
 * Creates a stream from a `Queue` of values.
 *
 * The queue will be shutdown once the stream is closed.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromChunkQueue = fromChunkQueue;
const fromChunkQueueWithShutdown = internal.fromChunkQueueWithShutdown;
/**
 * Creates a stream from an arbitrary number of chunks.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromChunkQueueWithShutdown = fromChunkQueueWithShutdown;
const fromChunks = internal.fromChunks;
/**
 * Either emits the success value of this effect or terminates the stream
 * with the failure value of this effect.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromChunks = fromChunks;
const fromEffect = internal.fromEffect;
/**
 * Creates a stream from an effect producing a value of type `A` or an empty
 * `Stream`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromEffect = fromEffect;
const fromEffectOption = internal.fromEffectOption;
/**
 * Creates a stream from a subscription to a `Hub`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromEffectOption = fromEffectOption;
const fromHub = internal.fromHub;
/**
 * Creates a stream from a subscription to a `Hub` in the context of a scoped
 * effect. The scoped effect describes subscribing to receive messages from
 * the hub while the stream describes taking messages from the hub.
 *
 * @macro traced
 * @since 1.0.0
 * @category constructors
 */
exports.fromHub = fromHub;
const fromHubScoped = internal.fromHubScoped;
/**
 * Creates a stream from a subscription to a `Hub`.
 *
 * The hub will be shut down once the stream is closed.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromHubScoped = fromHubScoped;
const fromHubWithShutdown = internal.fromHubWithShutdown;
/**
 * Creates a stream from a subscription to a `Hub` in the context of a scoped
 * effect. The scoped effect describes subscribing to receive messages from
 * the hub while the stream describes taking messages from the hub.
 *
 * The hub will be shut down once the stream is closed.
 *
 * @macro traced
 * @since 1.0.0
 * @category constructors
 */
exports.fromHubWithShutdown = fromHubWithShutdown;
const fromHubScopedWithShutdown = internal.fromHubScopedWithShutdown;
/**
 * Creates a stream from an `Iterable` collection of values.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromHubScopedWithShutdown = fromHubScopedWithShutdown;
const fromIterable = internal.fromIterable;
/**
 * Creates a stream from an effect producing a value of type `Iterable<A>`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromIterable = fromIterable;
const fromIterableEffect = internal.fromIterableEffect;
/**
 * Creates a stream from an iterator
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromIterableEffect = fromIterableEffect;
const fromIteratorSucceed = internal.fromIteratorSucceed;
/**
 * Creates a stream from an effect that pulls elements from another stream.
 *
 * See `Stream.toPull` for reference.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromIteratorSucceed = fromIteratorSucceed;
const fromPull = internal.fromPull;
/**
 * Creates a stream from a queue of values
 *
 * @param maxChunkSize The maximum number of queued elements to put in one chunk in the stream
 * @since 1.0.0
 * @category constructors
 */
exports.fromPull = fromPull;
const fromQueue = internal.fromQueue;
/**
 * Creates a stream from a queue of values. The queue will be shutdown once
 * the stream is closed.
 *
 * @param maxChunkSize The maximum number of queued elements to put in one chunk in the stream
 * @since 1.0.0
 * @category constructors
 */
exports.fromQueue = fromQueue;
const fromQueueWithShutdown = internal.fromQueueWithShutdown;
/**
 * Creates a stream from a `Schedule` that does not require any further
 * input. The stream will emit an element for each value output from the
 * schedule, continuing for as long as the schedule continues.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.fromQueueWithShutdown = fromQueueWithShutdown;
const fromSchedule = internal.fromSchedule;
/**
 * Creates a pipeline that groups on adjacent keys, calculated by the
 * specified function.
 *
 * @since 1.0.0
 * @category grouping
 */
exports.fromSchedule = fromSchedule;
const groupAdjacentBy = internal.groupAdjacentBy;
/**
 * More powerful version of `Stream.groupByKey`.
 *
 * @since 1.0.0
 * @category grouping
 */
exports.groupAdjacentBy = groupAdjacentBy;
const groupBy = _groupBy.groupBy;
/**
 * Like `groupBy`, but with a configurable `bufferSize` parameter.
 *
 * @since 1.0.0
 * @category grouping
 */
exports.groupBy = groupBy;
const groupByBuffer = _groupBy.groupByBuffer;
/**
 * Partition a stream using a function and process each stream individually.
 * This returns a data structure that can be used to further filter down which
 * groups shall be processed.
 *
 * After calling apply on the GroupBy object, the remaining groups will be
 * processed in parallel and the resulting streams merged in a
 * nondeterministic fashion.
 *
 * Up to `buffer` elements may be buffered in any group stream before the
 * producer is backpressured. Take care to consume from all streams in order
 * to prevent deadlocks.
 *
 * For example, to collect the first 2 words for every starting letter from a
 * stream of words:
 *
 * ```ts
 * import * as GroupBy from "@effect/stream/GroupBy"
 * import * as Stream from "@effect/stream/Stream"
 * import { pipe } from "@effect/data/Function"
 *
 * pipe(
 *   Stream.fromIterable(["hello", "world", "hi", "holla"]),
 *   Stream.groupByKey((word) => word[0]),
 *   GroupBy.evaluate((key, stream) =>
 *     pipe(
 *       stream,
 *       Stream.take(2),
 *       Stream.map((words) => [key, words] as const)
 *     )
 *   )
 * )
 * ```
 *
 * @since 1.0.0
 * @category utils
 */
exports.groupByBuffer = groupByBuffer;
const groupByKey = _groupBy.groupByKey;
/**
 * Like `groupByKey`, but with a configurable `bufferSize` parameter.
 *
 * @since 1.0.0
 * @category utils
 */
exports.groupByKey = groupByKey;
const groupByKeyBuffer = _groupBy.groupByKeyBuffer;
/**
 * Partitions the stream with specified `chunkSize`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.groupByKeyBuffer = groupByKeyBuffer;
const grouped = internal.grouped;
/**
 * Partitions the stream with the specified `chunkSize` or until the specified
 * `duration` has passed, whichever is satisfied first.
 *
 * @since 1.0.0
 * @category utils
 */
exports.grouped = grouped;
const groupedWithin = internal.groupedWithin;
/**
 * Specialized version of haltWhen which halts the evaluation of this stream
 * after the given duration.
 *
 * An element in the process of being pulled will not be interrupted when the
 * given duration completes. See `interruptAfter` for this behavior.
 *
 * @since 1.0.0
 * @category utils
 */
exports.groupedWithin = groupedWithin;
const haltAfter = internal.haltAfter;
/**
 * Halts the evaluation of this stream when the provided effect completes. The
 * given effect will be forked as part of the returned stream, and its success
 * will be discarded.
 *
 * An element in the process of being pulled will not be interrupted when the
 * effect completes. See `interruptWhen` for this behavior.
 *
 * If the effect completes with a failure, the stream will emit that failure.
 *
 * @since 1.0.0
 * @category utils
 */
exports.haltAfter = haltAfter;
const haltWhen = internal.haltWhen;
/**
 * Halts the evaluation of this stream when the provided promise resolves.
 *
 * If the promise completes with a failure, the stream will emit that failure.
 *
 * @since 1.0.0
 * @category utils
 */
exports.haltWhen = haltWhen;
const haltWhenDeferred = internal.haltWhenDeferred;
/**
 * The identity pipeline, which does not modify streams in any way.
 *
 * @since 1.0.0
 * @category utils
 */
exports.haltWhenDeferred = haltWhenDeferred;
const identity = internal.identityStream;
/**
 * Interleaves this stream and the specified stream deterministically by
 * alternating pulling values from this stream and the specified stream. When
 * one stream is exhausted all remaining values in the other stream will be
 * pulled.
 *
 * @since 1.0.0
 * @category utils
 */
exports.identity = identity;
const interleave = internal.interleave;
/**
 * Combines this stream and the specified stream deterministically using the
 * stream of boolean values `pull` to control which stream to pull from next.
 * A value of `true` indicates to pull from this stream and a value of `false`
 * indicates to pull from the specified stream. Only consumes as many elements
 * as requested by the `pull` stream. If either this stream or the specified
 * stream are exhausted further requests for values from that stream will be
 * ignored.
 *
 * @since 1.0.0
 * @category utils
 */
exports.interleave = interleave;
const interleaveWith = internal.interleaveWith;
/**
 * Intersperse stream with provided `element`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.interleaveWith = interleaveWith;
const intersperse = internal.intersperse;
/**
 * Intersperse the specified element, also adding a prefix and a suffix.
 *
 * @since 1.0.0
 * @category utils
 */
exports.intersperse = intersperse;
const intersperseAffixes = internal.intersperseAffixes;
/**
 * Specialized version of `Stream.interruptWhen` which interrupts the
 * evaluation of this stream after the given `Duration`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.intersperseAffixes = intersperseAffixes;
const interruptAfter = internal.interruptAfter;
/**
 * Interrupts the evaluation of this stream when the provided effect
 * completes. The given effect will be forked as part of this stream, and its
 * success will be discarded. This combinator will also interrupt any
 * in-progress element being pulled from upstream.
 *
 * If the effect completes with a failure before the stream completes, the
 * returned stream will emit that failure.
 *
 * @since 1.0.0
 * @category utils
 */
exports.interruptAfter = interruptAfter;
const interruptWhen = internal.interruptWhen;
/**
 * Interrupts the evaluation of this stream when the provided promise
 * resolves. This combinator will also interrupt any in-progress element being
 * pulled from upstream.
 *
 * If the promise completes with a failure, the stream will emit that failure.
 *
 * @since 1.0.0
 * @category utils
 */
exports.interruptWhen = interruptWhen;
const interruptWhenDeferred = internal.interruptWhenDeferred;
/**
 * The infinite stream of iterative function application: a, f(a), f(f(a)),
 * f(f(f(a))), ...
 *
 * @since 1.0.0
 * @category constructors
 */
exports.interruptWhenDeferred = interruptWhenDeferred;
const iterate = internal.iterate;
/**
 * Logs the specified message at the current log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.iterate = iterate;
const log = internal.log;
/**
 * Logs the specified message at the debug log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.log = log;
const logDebug = internal.logDebug;
/**
 * Logs the specified `Cause` at the debug log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logDebug = logDebug;
const logDebugCause = internal.logDebugCause;
/**
 * Logs the specified message and `Cause` at the debug log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logDebugCause = logDebugCause;
const logDebugCauseMessage = internal.logDebugCauseMessage;
/**
 * Logs the specified message at the error log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logDebugCauseMessage = logDebugCauseMessage;
const logError = internal.logError;
/**
 * Logs the specified `Cause` at the error log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logError = logError;
const logErrorCause = internal.logErrorCause;
/**
 * Logs the specified message and `Cause` at the error log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logErrorCause = logErrorCause;
const logErrorCauseMessage = internal.logErrorCauseMessage;
/**
 * Logs the specified message at the fatal log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logErrorCauseMessage = logErrorCauseMessage;
const logFatal = internal.logFatal;
/**
 * Logs the specified `Cause` at the fatal log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logFatal = logFatal;
const logFatalCause = internal.logFatalCause;
/**
 * Logs the specified message and `Cause` at the fatal log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logFatalCause = logFatalCause;
const logFatalCauseMessage = internal.logFatalCauseMessage;
/**
 * Logs the specified message at the info log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logFatalCauseMessage = logFatalCauseMessage;
const logInfo = internal.logInfo;
/**
 * Logs the specified `Cause` at the info log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logInfo = logInfo;
const logInfoCause = internal.logInfoCause;
/**
 * Logs the specified message and `Cause` at the info log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logInfoCause = logInfoCause;
const logInfoCauseMessage = internal.logInfoCauseMessage;
/**
 * Logs the specified message at the warning log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logInfoCauseMessage = logInfoCauseMessage;
const logWarning = internal.logWarning;
/**
 * Logs the specified `Cause` at the warning log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logWarning = logWarning;
const logWarningCause = internal.logWarningCause;
/**
 * Logs the specified message and `Cause` at the warning log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logWarningCause = logWarningCause;
const logWarningCauseMessage = internal.logWarningCauseMessage;
/**
 * Logs the specified message at the trace log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logWarningCauseMessage = logWarningCauseMessage;
const logTrace = internal.logTrace;
/**
 * Logs the specified `Cause` at the trace log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logTrace = logTrace;
const logTraceCause = internal.logTraceCause;
/**
 * Logs the specified message and `Cause` at the trace log level.
 *
 * @since 1.0.0
 * @category logging
 */
exports.logTraceCause = logTraceCause;
const logTraceCauseMessage = internal.logTraceCauseMessage;
/**
 * Creates a stream from an sequence of values.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.logTraceCauseMessage = logTraceCauseMessage;
const make = internal.make;
/**
 * Transforms the elements of this stream using the supplied function.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.make = make;
const map = internal.map;
/**
 * Statefully maps over the elements of this stream to produce new elements.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.map = map;
const mapAccum = internal.mapAccum;
/**
 * Statefully and effectfully maps over the elements of this stream to produce
 * new elements.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapAccum = mapAccum;
const mapAccumEffect = internal.mapAccumEffect;
/**
 * Returns a stream whose failure and success channels have been mapped by the
 * specified pair of functions, `f` and `g`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.mapAccumEffect = mapAccumEffect;
const mapBoth = internal.mapBoth;
/**
 * Transforms the chunks emitted by this stream.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapBoth = mapBoth;
const mapChunks = internal.mapChunks;
/**
 * Effectfully transforms the chunks emitted by this stream.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapChunks = mapChunks;
const mapChunksEffect = internal.mapChunksEffect;
/**
 * Maps each element to an iterable, and flattens the iterables into the
 * output of this stream.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapChunksEffect = mapChunksEffect;
const mapConcat = internal.mapConcat;
/**
 * Maps each element to a chunk, and flattens the chunks into the output of
 * this stream.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapConcat = mapConcat;
const mapConcatChunk = internal.mapConcatChunk;
/**
 * Effectfully maps each element to a chunk, and flattens the chunks into the
 * output of this stream.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapConcatChunk = mapConcatChunk;
const mapConcatChunkEffect = internal.mapConcatChunkEffect;
/**
 * Effectfully maps each element to an iterable, and flattens the iterables
 * into the output of this stream.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapConcatChunkEffect = mapConcatChunkEffect;
const mapConcatEffect = internal.mapConcatEffect;
/**
 * Maps over elements of the stream with the specified effectful function.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapConcatEffect = mapConcatEffect;
const mapEffect = internal.mapEffect;
/**
 * Transforms the errors emitted by this stream using `f`.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapEffect = mapEffect;
const mapError = internal.mapError;
/**
 * Transforms the full causes of failures emitted by this stream.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapError = mapError;
const mapErrorCause = internal.mapErrorCause;
/**
 * Maps over elements of the stream with the specified effectful function,
 * executing up to `n` invocations of `f` concurrently. Transformed elements
 * will be emitted in the original order.
 *
 * @note This combinator destroys the chunking structure. It's recommended to use
 *       rechunk afterwards.
 * @since 1.0.0
 * @category mapping
 */
exports.mapErrorCause = mapErrorCause;
const mapEffectPar = internal.mapEffectPar;
/**
 * Maps over elements of the stream with the specified effectful function,
 * partitioned by `p` executing invocations of `f` concurrently. The number of
 * concurrent invocations of `f` is determined by the number of different
 * outputs of type `K`. Up to `buffer` elements may be buffered per partition.
 * Transformed elements may be reordered but the order within a partition is
 * maintained.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapEffectPar = mapEffectPar;
const mapEffectParByKey = _groupBy.mapEffectParByKey;
/**
 * Like `mapEffectParByKey`, but with a `bufferSize` parameter.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapEffectParByKey = mapEffectParByKey;
const mapEffectParByKeyBuffer = _groupBy.mapEffectParByKeyBuffer;
/**
 * Maps over elements of the stream with the specified effectful function,
 * executing up to `n` invocations of `f` concurrently. The element order is
 * not enforced by this combinator, and elements may be reordered.
 *
 * @since 1.0.0
 * @category mapping
 */
exports.mapEffectParByKeyBuffer = mapEffectParByKeyBuffer;
const mapEffectParUnordered = internal.mapEffectParUnordered;
/**
 * Merges this stream and the specified stream together.
 *
 * New produced stream will terminate when both specified stream terminate if
 * no termination strategy is specified.
 *
 * @since 1.0.0
 * @category utils
 */
exports.mapEffectParUnordered = mapEffectParUnordered;
const merge = internal.merge;
/**
 * Like `merge`, but with a configurable `strategy` parameter.
 *
 * @since 1.0.0
 * @category utils
 */
exports.merge = merge;
const mergeHaltStrategy = internal.mergeHaltStrategy;
/**
 * Merges a variable list of streams in a non-deterministic fashion. Up to `n`
 * streams may be consumed in parallel and up to `outputBuffer` chunks may be
 * buffered by this operator.
 *
 * @since 1.0.0
 * @category utils
 */
exports.mergeHaltStrategy = mergeHaltStrategy;
const mergeAll = internal.mergeAll;
/**
 * Like `Stream.mergeAll`, but runs all streams concurrently.
 *
 * @since 1.0.0
 * @category utils
 */
exports.mergeAll = mergeAll;
const mergeAllUnbounded = internal.mergeAllUnbounded;
/**
 * Merges this stream and the specified stream together to a common element
 * type with the specified mapping functions.
 *
 * New produced stream will terminate when both specified stream terminate if
 * no termination strategy is specified.
 *
 * @since 1.0.0
 * @category utils
 */
exports.mergeAllUnbounded = mergeAllUnbounded;
const mergeWith = internal.mergeWith;
/**
 * Like `mergeWith`, but with a configurable `strategy` parameter.
 *
 * @since 1.0.0
 * @category utils
 */
exports.mergeWith = mergeWith;
const mergeWithHaltStrategy = internal.mergeWithHaltStrategy;
/**
 * Merges this stream and the specified stream together. New produced stream
 * will terminate when either stream terminates.
 *
 * @since 1.0.0
 * @category utils
 */
exports.mergeWithHaltStrategy = mergeWithHaltStrategy;
const mergeHaltEither = internal.mergeHaltEither;
/**
 * Merges this stream and the specified stream together. New produced stream
 * will terminate when this stream terminates.
 *
 * @since 1.0.0
 * @category utils
 */
exports.mergeHaltEither = mergeHaltEither;
const mergeHaltLeft = internal.mergeHaltLeft;
/**
 * Merges this stream and the specified stream together. New produced stream
 * will terminate when the specified stream terminates.
 *
 * @since 1.0.0
 * @category utils
 */
exports.mergeHaltLeft = mergeHaltLeft;
const mergeHaltRight = internal.mergeHaltRight;
/**
 * Merges this stream and the specified stream together to produce a stream of
 * eithers.
 *
 * @since 1.0.0
 * @category utils
 */
exports.mergeHaltRight = mergeHaltRight;
const mergeEither = internal.mergeEither;
/**
 * Merges this stream and the specified stream together, discarding the values
 * from the right stream.
 *
 * @since 1.0.0
 * @category utils
 */
exports.mergeEither = mergeEither;
const mergeLeft = internal.mergeLeft;
/**
 * Merges this stream and the specified stream together, discarding the values
 * from the left stream.
 *
 * @since 1.0.0
 * @category utils
 */
exports.mergeLeft = mergeLeft;
const mergeRight = internal.mergeRight;
/**
 * Returns a combined string resulting from concatenating each of the values
 * from the stream.
 *
 * @macro traced
 * @since 1.0.0
 * @category utils
 */
exports.mergeRight = mergeRight;
const mkString = internal.mkString;
/**
 * The stream that never produces any value or fails with any error.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.mkString = mkString;
const never = internal.never;
/**
 * Runs the specified effect if this stream fails, providing the error to the
 * effect if it exists.
 *
 * Note: Unlike `Effect.onError` there is no guarantee that the provided
 * effect will not be interrupted.
 *
 * @since 1.0.0
 * @category utils
 */
exports.never = never;
const onError = internal.onError;
/**
 * Runs the specified effect if this stream ends.
 *
 * @since 1.0.0
 * @category utils
 */
exports.onError = onError;
const onDone = internal.onDone;
/**
 * Translates any failure into a stream termination, making the stream
 * infallible and all failures unchecked.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.onDone = onDone;
const orDie = internal.orDie;
/**
 * Keeps none of the errors, and terminates the stream with them, using the
 * specified function to convert the `E` into a defect.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.orDie = orDie;
const orDieWith = internal.orDieWith;
/**
 * Switches to the provided stream in case this one fails with a typed error.
 *
 * See also `Stream.catchAll`.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.orDieWith = orDieWith;
const orElse = internal.orElse;
/**
 * Switches to the provided stream in case this one fails with a typed error.
 *
 * See also `Stream.catchAll`.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.orElse = orElse;
const orElseEither = internal.orElseEither;
/**
 * Fails with given error in case this one fails with a typed error.
 *
 * See also `Stream.catchAll`.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.orElseEither = orElseEither;
const orElseFail = internal.orElseFail;
/**
 * Produces the specified element if this stream is empty.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.orElseFail = orElseFail;
const orElseIfEmpty = internal.orElseIfEmpty;
/**
 * Produces the specified chunk if this stream is empty.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.orElseIfEmpty = orElseIfEmpty;
const orElseIfEmptyChunk = internal.orElseIfEmptyChunk;
/**
 * Switches to the provided stream in case this one is empty.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.orElseIfEmptyChunk = orElseIfEmptyChunk;
const orElseIfEmptyStream = internal.orElseIfEmptyStream;
/**
 * Switches to the provided stream in case this one fails with the `None`
 * value.
 *
 * See also `Stream.catchAll`.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.orElseIfEmptyStream = orElseIfEmptyStream;
const orElseOptional = internal.orElseOptional;
/**
 * Succeeds with the specified value if this one fails with a typed error.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.orElseOptional = orElseOptional;
const orElseSucceed = internal.orElseSucceed;
/**
 * Like `Stream.unfold`, but allows the emission of values to end one step further
 * than the unfolding of the state. This is useful for embedding paginated
 * APIs, hence the name.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.orElseSucceed = orElseSucceed;
const paginate = internal.paginate;
/**
 * Like `Stream.unfoldChunk`, but allows the emission of values to end one step
 * further than the unfolding of the state. This is useful for embedding
 * paginated APIs, hence the name.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.paginate = paginate;
const paginateChunk = internal.paginateChunk;
/**
 * Like `Stream.unfoldChunkEffect`, but allows the emission of values to end one step
 * further than the unfolding of the state. This is useful for embedding
 * paginated APIs, hence the name.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.paginateChunk = paginateChunk;
const paginateChunkEffect = internal.paginateChunkEffect;
/**
 * Like `Stream.unfoldEffect` but allows the emission of values to end one step
 * further than the unfolding of the state. This is useful for embedding
 * paginated APIs, hence the name.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.paginateChunkEffect = paginateChunkEffect;
const paginateEffect = internal.paginateEffect;
/**
 * Partition a stream using a predicate. The first stream will contain all
 * element evaluated to true and the second one will contain all element
 * evaluated to false. The faster stream may advance by up to buffer elements
 * further than the slower one.
 *
 * @since 1.0.0
 * @category utils
 */
exports.paginateEffect = paginateEffect;
const partition = internal.partition;
/**
 * Like `partition`, but with a configurable `bufferSize` parameter.
 *
 * @since 1.0.0
 * @category utils
 */
exports.partition = partition;
const partitionBuffer = internal.partitionBuffer;
/**
 * Split a stream by an effectful predicate. The faster stream may advance by
 * up to buffer elements further than the slower one.
 *
 * @since 1.0.0
 * @category utils
 */
exports.partitionBuffer = partitionBuffer;
const partitionEither = internal.partitionEither;
/**
 * Like `partitionEither`, but with a configurable `bufferSize` parameter.
 *
 * @since 1.0.0
 * @category utils
 */
exports.partitionEither = partitionEither;
const partitionEitherBuffer = internal.partitionEitherBuffer;
/**
 * Peels off enough material from the stream to construct a `Z` using the
 * provided `Sink` and then returns both the `Z` and the rest of the
 * `Stream` in a scope. Like all scoped values, the provided stream is
 * valid only within the scope.
 *
 * @macro traced
 * @since 1.0.0
 * @category utils
 */
exports.partitionEitherBuffer = partitionEitherBuffer;
const peel = internal.peel;
/**
 * Pipes all of the values from this stream through the provided sink.
 *
 * See also `Stream.transduce`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.peel = peel;
const pipeThrough = internal.pipeThrough;
/**
 * Pipes all the values from this stream through the provided channel.
 *
 * @since 1.0.0
 * @category utils
 */
exports.pipeThrough = pipeThrough;
const pipeThroughChannel = internal.pipeThroughChannel;
/**
 * Pipes all values from this stream through the provided channel, passing
 * through any error emitted by this stream unchanged.
 *
 * @since 1.0.0
 * @category utils
 */
exports.pipeThroughChannel = pipeThroughChannel;
const pipeThroughChannelOrFail = internal.pipeThroughChannelOrFail;
/**
 * Emits the provided chunk before emitting any other value.
 *
 * @since 1.0.0
 * @category utils
 */
exports.pipeThroughChannelOrFail = pipeThroughChannelOrFail;
const prepend = internal.prepend;
/**
 * Provides the stream with its required context, which eliminates its
 * dependency on `R`.
 *
 * @since 1.0.0
 * @category context
 */
exports.prepend = prepend;
const provideContext = internal.provideContext;
/**
 * Provides a `Layer` to the stream, which translates it to another level.
 *
 * @since 1.0.0
 * @category context
 */
exports.provideContext = provideContext;
const provideLayer = internal.provideLayer;
/**
 * Provides the stream with the single service it requires. If the stream
 * requires more than one service use `Stream.provideContext` instead.
 *
 * @since 1.0.0
 * @category context
 */
exports.provideLayer = provideLayer;
const provideService = internal.provideService;
/**
 * Provides the stream with the single service it requires. If the stream
 * requires more than one service use `Stream.provideContext` instead.
 *
 * @since 1.0.0
 * @category context
 */
exports.provideService = provideService;
const provideServiceEffect = internal.provideServiceEffect;
/**
 * Provides the stream with the single service it requires. If the stream
 * requires more than one service use `Stream.provideContext` instead.
 *
 * @since 1.0.0
 * @category context
 */
exports.provideServiceEffect = provideServiceEffect;
const provideServiceStream = internal.provideServiceStream;
/**
 * Transforms the context being provided to the stream with the specified
 * function.
 *
 * @since 1.0.0
 * @category context
 */
exports.provideServiceStream = provideServiceStream;
const contramapContext = internal.contramapContext;
/**
 * Splits the context into two parts, providing one part using the
 * specified layer and leaving the remainder `R0`.
 *
 * @since 1.0.0
 * @category context
 */
exports.contramapContext = contramapContext;
const provideSomeLayer = internal.provideSomeLayer;
/**
 * Constructs a stream from a range of integers (lower bound included, upper
 * bound not included).
 *
 * @since 1.0.0
 * @category constructors
 */
exports.provideSomeLayer = provideSomeLayer;
const range = internal.range;
/**
 * Re-chunks the elements of the stream into chunks of `n` elements each. The
 * last chunk might contain less than `n` elements.
 *
 * @since 1.0.0
 * @category utils
 */
exports.range = range;
const rechunk = internal.rechunk;
/**
 * Keeps some of the errors, and terminates the fiber with the rest
 *
 * @since 1.0.0
 * @category error handling
 */
exports.rechunk = rechunk;
const refineOrDie = internal.refineOrDie;
/**
 * Keeps some of the errors, and terminates the fiber with the rest, using the
 * specified function to convert the `E` into a defect.
 *
 * @since 1.0.0
 * @category error handling
 */
exports.refineOrDie = refineOrDie;
const refineOrDieWith = internal.refineOrDieWith;
/**
 * Repeats the entire stream using the specified schedule. The stream will
 * execute normally, and then repeat again according to the provided schedule.
 *
 * @since 1.0.0
 * @category utils
 */
exports.refineOrDieWith = refineOrDieWith;
const repeat = internal.repeat;
/**
 * Creates a stream from an effect producing a value of type `A` which repeats
 * forever.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.repeat = repeat;
const repeatEffect = internal.repeatEffect;
/**
 * Creates a stream from an effect producing chunks of `A` values which
 * repeats forever.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.repeatEffect = repeatEffect;
const repeatEffectChunk = internal.repeatEffectChunk;
/**
 * Creates a stream from an effect producing chunks of `A` values until it
 * fails with `None`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.repeatEffectChunk = repeatEffectChunk;
const repeatEffectChunkOption = internal.repeatEffectChunkOption;
/**
 * Creates a stream from an effect producing values of type `A` until it fails
 * with `None`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.repeatEffectChunkOption = repeatEffectChunkOption;
const repeatEffectOption = internal.repeatEffectOption;
/**
 * Creates a stream from an effect producing a value of type `A`, which is
 * repeated using the specified schedule.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.repeatEffectOption = repeatEffectOption;
const repeatEffectWithSchedule = internal.repeatEffectWithSchedule;
/**
 * Repeats the entire stream using the specified schedule. The stream will
 * execute normally, and then repeat again according to the provided schedule.
 * The schedule output will be emitted at the end of each repetition.
 *
 * @since 1.0.0
 * @category utils
 */
exports.repeatEffectWithSchedule = repeatEffectWithSchedule;
const repeatEither = internal.repeatEither;
/**
 * Repeats each element of the stream using the provided schedule. Repetitions
 * are done in addition to the first execution, which means using
 * `Schedule.recurs(1)` actually results in the original effect, plus an
 * additional recurrence, for a total of two repetitions of each value in the
 * stream.
 *
 * @since 1.0.0
 * @category utils
 */
exports.repeatEither = repeatEither;
const repeatElements = internal.repeatElements;
/**
 * Repeats each element of the stream using the provided schedule. When the
 * schedule is finished, then the output of the schedule will be emitted into
 * the stream. Repetitions are done in addition to the first execution, which
 * means using `Schedule.recurs(1)` actually results in the original effect,
 * plus an additional recurrence, for a total of two repetitions of each value
 * in the stream.
 *
 * @since 1.0.0
 * @category utils
 */
exports.repeatElements = repeatElements;
const repeatElementsEither = internal.repeatElementsEither;
/**
 * Repeats each element of the stream using the provided schedule. When the
 * schedule is finished, then the output of the schedule will be emitted into
 * the stream. Repetitions are done in addition to the first execution, which
 * means using `Schedule.recurs(1)` actually results in the original effect,
 * plus an additional recurrence, for a total of two repetitions of each value
 * in the stream.
 *
 * This function accepts two conversion functions, which allow the output of
 * this stream and the output of the provided schedule to be unified into a
 * single type. For example, `Either` or similar data type.
 *
 * @since 1.0.0
 * @category utils
 */
exports.repeatElementsEither = repeatElementsEither;
const repeatElementsWith = internal.repeatElementsWith;
/**
 * Repeats the provided value infinitely.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.repeatElementsWith = repeatElementsWith;
const repeatValue = internal.repeatValue;
/**
 * Repeats the entire stream using the specified schedule. The stream will
 * execute normally, and then repeat again according to the provided schedule.
 * The schedule output will be emitted at the end of each repetition and can
 * be unified with the stream elements using the provided functions.
 *
 * @since 1.0.0
 * @category utils
 */
exports.repeatValue = repeatValue;
const repeatWith = internal.repeatWith;
/**
 * When the stream fails, retry it according to the given schedule
 *
 * This retries the entire stream, so will re-execute all of the stream's
 * acquire operations.
 *
 * The schedule is reset as soon as the first element passes through the
 * stream again.
 *
 * @param schedule A `Schedule` receiving as input the errors of the stream.
 * @since 1.0.0
 * @category utils
 */
exports.repeatWith = repeatWith;
const retry = internal.retry;
/**
 * Fails with the error `None` if value is `Left`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.retry = retry;
const right = internal.right;
/**
 * Fails with given error 'e' if value is `Left`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.right = right;
const rightOrFail = internal.rightOrFail;
/**
 * Runs the sink on the stream to produce either the sink's result or an error.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.rightOrFail = rightOrFail;
const run = internal.run;
/**
 * Runs the stream and collects all of its elements to a chunk.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.run = run;
const runCollect = internal.runCollect;
/**
 * Runs the stream and emits the number of elements processed
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runCollect = runCollect;
const runCount = internal.runCount;
/**
 * Runs the stream only for its effects. The emitted elements are discarded.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runCount = runCount;
const runDrain = internal.runDrain;
/**
 * Executes a pure fold over the stream of values - reduces all elements in
 * the stream to a value of type `S`.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runDrain = runDrain;
const runFold = internal.runFold;
/**
 * Executes an effectful fold over the stream of values.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runFold = runFold;
const runFoldEffect = internal.runFoldEffect;
/**
 * Executes a pure fold over the stream of values. Returns a scoped value that
 * represents the scope of the stream.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runFoldEffect = runFoldEffect;
const runFoldScoped = internal.runFoldScoped;
/**
 * Executes an effectful fold over the stream of values. Returns a scoped
 * value that represents the scope of the stream.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runFoldScoped = runFoldScoped;
const runFoldScopedEffect = internal.runFoldScopedEffect;
/**
 * Reduces the elements in the stream to a value of type `S`. Stops the fold
 * early when the condition is not fulfilled. Example:
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runFoldScopedEffect = runFoldScopedEffect;
const runFoldWhile = internal.runFoldWhile;
/**
 * Executes an effectful fold over the stream of values. Stops the fold early
 * when the condition is not fulfilled.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runFoldWhile = runFoldWhile;
const runFoldWhileEffect = internal.runFoldWhileEffect;
/**
 * Executes a pure fold over the stream of values. Returns a scoped value that
 * represents the scope of the stream. Stops the fold early when the condition
 * is not fulfilled.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runFoldWhileEffect = runFoldWhileEffect;
const runFoldWhileScoped = internal.runFoldWhileScoped;
/**
 * Executes an effectful fold over the stream of values. Returns a scoped
 * value that represents the scope of the stream. Stops the fold early when
 * the condition is not fulfilled.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runFoldWhileScoped = runFoldWhileScoped;
const runFoldWhileScopedEffect = internal.runFoldWhileScopedEffect;
/**
 * Consumes all elements of the stream, passing them to the specified
 * callback.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runFoldWhileScopedEffect = runFoldWhileScopedEffect;
const runForEach = internal.runForEach;
/**
 * Consumes all elements of the stream, passing them to the specified
 * callback.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runForEach = runForEach;
const runForEachChunk = internal.runForEachChunk;
/**
 * Like `Stream.runForEachChunk`, but returns a scoped effect so the
 * finalization order can be controlled.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runForEachChunk = runForEachChunk;
const runForEachChunkScoped = internal.runForEachChunkScoped;
/**
 * Like `Stream.forEach`, but returns a scoped effect so the finalization
 * order can be controlled.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runForEachChunkScoped = runForEachChunkScoped;
const runForEachScoped = internal.runForEachScoped;
/**
 * Consumes elements of the stream, passing them to the specified callback,
 * and terminating consumption when the callback returns `false`.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runForEachScoped = runForEachScoped;
const runForEachWhile = internal.runForEachWhile;
/**
 * Like `Stream.runForEachWhile`, but returns a scoped effect so the
 * finalization order can be controlled.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runForEachWhile = runForEachWhile;
const runForEachWhileScoped = internal.runForEachWhileScoped;
/**
 * Runs the stream to completion and yields the first value emitted by it,
 * discarding the rest of the elements.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runForEachWhileScoped = runForEachWhileScoped;
const runHead = internal.runHead;
/**
 * Publishes elements of this stream to a hub. Stream failure and ending will
 * also be signalled.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runHead = runHead;
const runIntoHub = internal.runIntoHub;
/**
 * Like `Stream.runIntoHub`, but provides the result as a scoped effect to
 * allow for scope composition.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runIntoHub = runIntoHub;
const runIntoHubScoped = internal.runIntoHubScoped;
/**
 * Enqueues elements of this stream into a queue. Stream failure and ending
 * will also be signalled.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runIntoHubScoped = runIntoHubScoped;
const runIntoQueue = internal.runIntoQueue;
/**
 * Like `Stream.runIntoQueue`, but provides the result as a scoped [[ZIO]]
 * to allow for scope composition.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runIntoQueue = runIntoQueue;
const runIntoQueueElementsScoped = internal.runIntoQueueElementsScoped;
/**
 * Like `Stream.runIntoQueue`, but provides the result as a scoped effect
 * to allow for scope composition.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runIntoQueueElementsScoped = runIntoQueueElementsScoped;
const runIntoQueueScoped = internal.runIntoQueueScoped;
/**
 * Runs the stream to completion and yields the last value emitted by it,
 * discarding the rest of the elements.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runIntoQueueScoped = runIntoQueueScoped;
const runLast = internal.runLast;
/**
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runLast = runLast;
const runScoped = internal.runScoped;
/**
 * Runs the stream to a sink which sums elements, provided they are Numeric.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.runScoped = runScoped;
const runSum = internal.runSum;
/**
 * Statefully maps over the elements of this stream to produce all
 * intermediate results of type `S` given an initial S.
 *
 * @since 1.0.0
 * @category utils
 */
exports.runSum = runSum;
const scan = internal.scan;
/**
 * Statefully and effectfully maps over the elements of this stream to produce
 * all intermediate results of type `S` given an initial S.
 *
 * @since 1.0.0
 * @category utils
 */
exports.scan = scan;
const scanEffect = internal.scanEffect;
/**
 * Statefully maps over the elements of this stream to produce all
 * intermediate results.
 *
 * See also `Stream.scan`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.scanEffect = scanEffect;
const scanReduce = internal.scanReduce;
/**
 * Statefully and effectfully maps over the elements of this stream to produce
 * all intermediate results.
 *
 * See also `Stream.scanEffect`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.scanReduce = scanReduce;
const scanReduceEffect = internal.scanReduceEffect;
/**
 * Schedules the output of the stream using the provided `schedule`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.scanReduceEffect = scanReduceEffect;
const schedule = internal.schedule;
/**
 * Schedules the output of the stream using the provided `schedule` and emits
 * its output at the end (if `schedule` is finite).
 *
 * @since 1.0.0
 * @category utils
 */
exports.schedule = schedule;
const scheduleEither = internal.scheduleEither;
/**
 * Schedules the output of the stream using the provided `schedule` and emits
 * its output at the end (if `schedule` is finite). Uses the provided function
 * to align the stream and schedule outputs on the same type.
 *
 * @since 1.0.0
 * @category utils
 */
exports.scheduleEither = scheduleEither;
const scheduleWith = internal.scheduleWith;
/**
 * Creates a single-valued stream from a scoped resource.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.scheduleWith = scheduleWith;
const scoped = internal.scoped;
/**
 * Emits a sliding window of `n` elements.
 *
 * ```ts
 * import * as Stream from "@effect/stream/Stream"
 * import { pipe } from "@effect/data/Function"
 *
 * pipe(
 *   Stream.make(1, 2, 3, 4),
 *   Stream.sliding(2),
 *   Stream.runCollect
 * )
 * // => Chunk(Chunk(1, 2), Chunk(2, 3), Chunk(3, 4))
 * ```
 *
 * @since 1.0.0
 * @category utils
 */
exports.scoped = scoped;
const sliding = internal.sliding;
/**
 * Like `sliding`, but with a configurable `stepSize` parameter.
 *
 * @since 1.0.0
 * @category utils
 */
exports.sliding = sliding;
const slidingSize = internal.slidingSize;
/**
 * Converts an option on values into an option on errors.
 *
 * @since 1.0.0
 * @category utils
 */
exports.slidingSize = slidingSize;
const some = internal.some;
/**
 * Extracts the optional value, or returns the given 'default'.
 *
 * @since 1.0.0
 * @category utils
 */
exports.some = some;
const someOrElse = internal.someOrElse;
/**
 * Extracts the optional value, or fails with the given error 'e'.
 *
 * @since 1.0.0
 * @category utils
 */
exports.someOrElse = someOrElse;
const someOrFail = internal.someOrFail;
/**
 * Splits elements based on a predicate.
 *
 * ```ts
 * import * as Stream from "@effect/stream/Stream"
 * import { pipe } from "@effect/data/Function"
 *
 * pipe(
 *   Stream.range(1, 10),
 *   Stream.split((n) => n % 4 === 0),
 *   Stream.runCollect
 * )
 * // => Chunk(Chunk(1, 2, 3), Chunk(5, 6, 7), Chunk(9))
 * ```
 *
 * @since 1.0.0
 * @category utils
 */
exports.someOrFail = someOrFail;
const split = internal.split;
/**
 * Splits elements on a delimiter and transforms the splits into desired output.
 *
 * @since 1.0.0
 * @category utils
 */
exports.split = split;
const splitOnChunk = internal.splitOnChunk;
/**
 * Creates a single-valued pure stream.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.splitOnChunk = splitOnChunk;
const succeed = internal.succeed;
/**
 * Creates a single-valued pure stream.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.succeed = succeed;
const sync = internal.sync;
/**
 * Returns a lazily constructed stream.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.sync = sync;
const suspend = internal.suspend;
/**
 * Takes the specified number of elements from this stream.
 *
 * @since 1.0.0
 * @category utils
 */
exports.suspend = suspend;
const take = internal.take;
/**
 * Takes the last specified number of elements from this stream.
 *
 * @since 1.0.0
 * @category utils
 */
exports.take = take;
const takeRight = internal.takeRight;
/**
 * Takes all elements of the stream until the specified predicate evaluates to
 * `true`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.takeRight = takeRight;
const takeUntil = internal.takeUntil;
/**
 * Takes all elements of the stream until the specified effectual predicate
 * evaluates to `true`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.takeUntil = takeUntil;
const takeUntilEffect = internal.takeUntilEffect;
/**
 * Takes all elements of the stream for as long as the specified predicate
 * evaluates to `true`.
 *
 * @since 1.0.0
 * @category utils
 */
exports.takeUntilEffect = takeUntilEffect;
const takeWhile = internal.takeWhile;
/**
 * Adds an effect to consumption of every element of the stream.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.takeWhile = takeWhile;
const tap = internal.tap;
/**
 * Returns a stream that effectfully "peeks" at the failure of the stream.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.tap = tap;
const tapError = internal.tapError;
/**
 * Returns a stream that effectfully "peeks" at the cause of failure of the
 * stream.
 *
 * @since 1.0.0
 * @category utils
 */
exports.tapError = tapError;
const tapErrorCause = internal.tapErrorCause;
/**
 * Sends all elements emitted by this stream to the specified sink in addition
 * to emitting them.
 *
 * @since 1.0.0
 * @category sequencing
 */
exports.tapErrorCause = tapErrorCause;
const tapSink = internal.tapSink;
/**
 * Throttles the chunks of this stream according to the given bandwidth
 * parameters using the token bucket algorithm. Allows for burst in the
 * processing of elements by allowing the token bucket to accumulate tokens up
 * to a `units + burst` threshold. Chunks that do not meet the bandwidth
 * constraints are dropped. The weight of each chunk is determined by the
 * `costFn` function.
 *
 * @since 1.0.0
 * @category utils
 */
exports.tapSink = tapSink;
const throttleEnforce = internal.throttleEnforce;
/**
 * Like `throttleEnforce`, but with a configurable `burst` parameter.
 *
 * @since 1.0.0
 * @category utils
 */
exports.throttleEnforce = throttleEnforce;
const throttleEnforceBurst = internal.throttleEnforceBurst;
/**
 * Throttles the chunks of this stream according to the given bandwidth
 * parameters using the token bucket algorithm. Allows for burst in the
 * processing of elements by allowing the token bucket to accumulate tokens up
 * to a `units + burst` threshold. Chunks that do not meet the bandwidth
 * constraints are dropped. The weight of each chunk is determined by the
 * `costFn` effectful function.
 *
 * @since 1.0.0
 * @category utils
 */
exports.throttleEnforceBurst = throttleEnforceBurst;
const throttleEnforceEffect = internal.throttleEnforceEffect;
/**
 * Like `throttleEnforceEffect`, but with a configurable `burst` parameter.
 *
 * @since 1.0.0
 * @category utils
 */
exports.throttleEnforceEffect = throttleEnforceEffect;
const throttleEnforceEffectBurst = internal.throttleEnforceEffectBurst;
/**
 * Delays the chunks of this stream according to the given bandwidth
 * parameters using the token bucket algorithm. Allows for burst in the
 * processing of elements by allowing the token bucket to accumulate tokens up
 * to a `units + burst` threshold. The weight of each chunk is determined by
 * the `costFn` function.
 *
 * @since 1.0.0
 * @category utils
 */
exports.throttleEnforceEffectBurst = throttleEnforceEffectBurst;
const throttleShape = internal.throttleShape;
/**
 * Like `throttleShape`, but with a configurable `burst` parameter.
 *
 * @since 1.0.0
 * @category utils
 */
exports.throttleShape = throttleShape;
const throttleShapeBurst = internal.throttleShapeBurst;
/**
 * Delays the chunks of this stream according to the given bandwidth
 * parameters using the token bucket algorithm. Allows for burst in the
 * processing of elements by allowing the token bucket to accumulate tokens up
 * to a `units + burst` threshold. The weight of each chunk is determined by
 * the `costFn` effectful function.
 *
 * @since 1.0.0
 * @category utils
 */
exports.throttleShapeBurst = throttleShapeBurst;
const throttleShapeEffect = internal.throttleShapeEffect;
/**
 * Like `throttleShapeEffect`, but with a configurable `burst` parameter.
 *
 * @since 1.0.0
 * @category utils
 */
exports.throttleShapeEffect = throttleShapeEffect;
const throttleShapeEffectBurst = internal.throttleShapeEffectBurst;
/**
 * A stream that emits Unit values spaced by the specified duration.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.throttleShapeEffectBurst = throttleShapeEffectBurst;
const tick = internal.tick;
/**
 * Ends the stream if it does not produce a value after the specified duration.
 *
 * @since 1.0.0
 * @category utils
 */
exports.tick = tick;
const timeout = internal.timeout;
/**
 * Fails the stream with given error if it does not produce a value after d
 * duration.
 *
 * @since 1.0.0
 * @category utils
 */
exports.timeout = timeout;
const timeoutFail = internal.timeoutFail;
/**
 * Fails the stream with given cause if it does not produce a value after d
 * duration.
 *
 * @since 1.0.0
 * @category utils
 */
exports.timeoutFail = timeoutFail;
const timeoutFailCause = internal.timeoutFailCause;
/**
 * Switches the stream if it does not produce a value after the specified
 * duration.
 *
 * @since 1.0.0
 * @category utils
 */
exports.timeoutFailCause = timeoutFailCause;
const timeoutTo = internal.timeoutTo;
/**
 * Converts the stream to a scoped hub of chunks. After the scope is closed,
 * the hub will never again produce values and should be discarded.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.timeoutTo = timeoutTo;
const toHub = internal.toHub;
/**
 * Returns in a scope a ZIO effect that can be used to repeatedly pull chunks
 * from the stream. The pull effect fails with None when the stream is
 * finished, or with Some error if it fails, otherwise it returns a chunk of
 * the stream's output.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.toHub = toHub;
const toPull = internal.toPull;
/**
 * Converts the stream to a scoped queue of chunks. After the scope is closed,
 * the queue will never again produce values and should be discarded.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.toPull = toPull;
const toQueue = internal.toQueue;
/**
 * Like `toQueue`, but with a configurable `capacity` parameter.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.toQueue = toQueue;
const toQueueCapacity = internal.toQueueCapacity;
/**
 * Converts the stream to a dropping scoped queue of chunks. After the scope
 * is closed, the queue will never again produce values and should be
 * discarded.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.toQueueCapacity = toQueueCapacity;
const toQueueDropping = internal.toQueueDropping;
/**
 * Like `toQueueDropping`, but with a configurable `capacity` parameter.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.toQueueDropping = toQueueDropping;
const toQueueDroppingCapacity = internal.toQueueDroppingCapacity;
/**
 * Converts the stream to a scoped queue of elements. After the scope is
 * closed, the queue will never again produce values and should be discarded.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.toQueueDroppingCapacity = toQueueDroppingCapacity;
const toQueueOfElements = internal.toQueueOfElements;
/**
 * Like `toQueueOfElements`, but with a configurable `capacity` parameter.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.toQueueOfElements = toQueueOfElements;
const toQueueOfElementsCapacity = internal.toQueueOfElementsCapacity;
/**
 * Converts the stream to a sliding scoped queue of chunks. After the scope is
 * closed, the queue will never again produce values and should be discarded.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.toQueueOfElementsCapacity = toQueueOfElementsCapacity;
const toQueueSliding = internal.toQueueSliding;
/**
 * Like `toQueueSliding`, but with a configurable `capacity` parameter.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.toQueueSliding = toQueueSliding;
const toQueueSlidingCapacity = internal.toQueueSlidingCapacity;
/**
 * Converts the stream into an unbounded scoped queue. After the scope is
 * closed, the queue will never again produce values and should be discarded.
 *
 * @macro traced
 * @since 1.0.0
 * @category destructors
 */
exports.toQueueSlidingCapacity = toQueueSlidingCapacity;
const toQueueUnbounded = internal.toQueueUnbounded;
/**
 * Applies the transducer to the stream and emits its outputs.
 *
 * @since 1.0.0
 * @category utils
 */
exports.toQueueUnbounded = toQueueUnbounded;
const transduce = internal.transduce;
/**
 * Creates a stream by peeling off the "layers" of a value of type `S`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.transduce = transduce;
const unfold = internal.unfold;
/**
 * Creates a stream by peeling off the "layers" of a value of type `S`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.unfold = unfold;
const unfoldChunk = internal.unfoldChunk;
/**
 * Creates a stream by effectfully peeling off the "layers" of a value of type
 * `S`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.unfoldChunk = unfoldChunk;
const unfoldChunkEffect = internal.unfoldChunkEffect;
/**
 * Creates a stream by effectfully peeling off the "layers" of a value of type
 * `S`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.unfoldChunkEffect = unfoldChunkEffect;
const unfoldEffect = internal.unfoldEffect;
/**
 * A stream that contains a single `Unit` value.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.unfoldEffect = unfoldEffect;
const unit = internal.unit;
/**
 * Creates a stream produced from an `Effect`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.unit = unit;
const unwrap = internal.unwrap;
/**
 * Creates a stream produced from a scoped `Effect`.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.unwrap = unwrap;
const unwrapScoped = internal.unwrapScoped;
/**
 * Updates the specified service within the context of the `Stream`.
 *
 * @since 1.0.0
 * @category context
 */
exports.unwrapScoped = unwrapScoped;
const updateService = internal.updateService;
/**
 * Returns the specified stream if the given condition is satisfied, otherwise
 * returns an empty stream.
 *
 * @since 1.0.0
 * @category utils
 */
exports.updateService = updateService;
const when = internal.when;
/**
 * Returns the resulting stream when the given `PartialFunction` is defined
 * for the given value, otherwise returns an empty stream.
 *
 * @since 1.0.0
 * @category constructors
 */
exports.when = when;
const whenCase = internal.whenCase;
/**
 * Returns the stream when the given partial function is defined for the given
 * effectful value, otherwise returns an empty stream.
 *
 * @since 1.0.0
 * @category utils
 */
exports.whenCase = whenCase;
const whenCaseEffect = internal.whenCaseEffect;
/**
 * Returns the stream if the given effectful condition is satisfied, otherwise
 * returns an empty stream.
 *
 * @since 1.0.0
 * @category utils
 */
exports.whenCaseEffect = whenCaseEffect;
const whenEffect = internal.whenEffect;
/**
 * Zips this stream with another point-wise and emits tuples of elements from
 * both streams.
 *
 * The new stream will end when one of the sides ends.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.whenEffect = whenEffect;
const zip = internal.zip;
/**
 * Zips this stream with another point-wise and emits tuples of elements from
 * both streams.
 *
 * The new stream will end when one of the sides ends.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zip = zip;
const zipFlatten = internal.zipFlatten;
/**
 * Zips this stream with another point-wise, creating a new stream of pairs of
 * elements from both sides.
 *
 * The defaults `defaultLeft` and `defaultRight` will be used if the streams
 * have different lengths and one of the streams has ended before the other.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipFlatten = zipFlatten;
const zipAll = internal.zipAll;
/**
 * Zips this stream with another point-wise, and keeps only elements from this
 * stream.
 *
 * The provided default value will be used if the other stream ends before
 * this one.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipAll = zipAll;
const zipAllLeft = internal.zipAllLeft;
/**
 * Zips this stream with another point-wise, and keeps only elements from the
 * other stream.
 *
 * The provided default value will be used if this stream ends before the
 * other one.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipAllLeft = zipAllLeft;
const zipAllRight = internal.zipAllRight;
/**
 * Zips this stream that is sorted by distinct keys and the specified stream
 * that is sorted by distinct keys to produce a new stream that is sorted by
 * distinct keys. Combines values associated with each key into a tuple,
 * using the specified values `defaultLeft` and `defaultRight` to fill in
 * missing values.
 *
 * This allows zipping potentially unbounded streams of data by key in
 * constant space but the caller is responsible for ensuring that the
 * streams are sorted by distinct keys.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipAllRight = zipAllRight;
const zipAllSortedByKey = internal.zipAllSortedByKey;
/**
 * Zips this stream that is sorted by distinct keys and the specified stream
 * that is sorted by distinct keys to produce a new stream that is sorted by
 * distinct keys. Keeps only values from this stream, using the specified
 * value `default` to fill in missing values.
 *
 * This allows zipping potentially unbounded streams of data by key in
 * constant space but the caller is responsible for ensuring that the
 * streams are sorted by distinct keys.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipAllSortedByKey = zipAllSortedByKey;
const zipAllSortedByKeyLeft = internal.zipAllSortedByKeyLeft;
/**
 * Zips this stream that is sorted by distinct keys and the specified stream
 * that is sorted by distinct keys to produce a new stream that is sorted by
 * distinct keys. Keeps only values from that stream, using the specified
 * value `default` to fill in missing values.
 *
 * This allows zipping potentially unbounded streams of data by key in
 * constant space but the caller is responsible for ensuring that the
 * streams are sorted by distinct keys.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipAllSortedByKeyLeft = zipAllSortedByKeyLeft;
const zipAllSortedByKeyRight = internal.zipAllSortedByKeyRight;
/**
 * Zips this stream that is sorted by distinct keys and the specified stream
 * that is sorted by distinct keys to produce a new stream that is sorted by
 * distinct keys. Uses the functions `left`, `right`, and `both` to handle
 * the cases where a key and value exist in this stream, that stream, or
 * both streams.
 *
 * This allows zipping potentially unbounded streams of data by key in
 * constant space but the caller is responsible for ensuring that the
 * streams are sorted by distinct keys.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipAllSortedByKeyRight = zipAllSortedByKeyRight;
const zipAllSortedByKeyWith = internal.zipAllSortedByKeyWith;
/**
 * Zips this stream with another point-wise. The provided functions will be
 * used to create elements for the composed stream.
 *
 * The functions `left` and `right` will be used if the streams have different
 * lengths and one of the streams has ended before the other.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipAllSortedByKeyWith = zipAllSortedByKeyWith;
const zipAllWith = internal.zipAllWith;
/**
 * Zips the two streams so that when a value is emitted by either of the two
 * streams, it is combined with the latest value from the other stream to
 * produce a result.
 *
 * Note: tracking the latest value is done on a per-chunk basis. That means
 * that emitted elements that are not the last value in chunks will never be
 * used for zipping.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipAllWith = zipAllWith;
const zipLatest = internal.zipLatest;
/**
 * Zips the two streams so that when a value is emitted by either of the two
 * streams, it is combined with the latest value from the other stream to
 * produce a result.
 *
 * Note: tracking the latest value is done on a per-chunk basis. That means
 * that emitted elements that are not the last value in chunks will never be
 * used for zipping.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipLatest = zipLatest;
const zipLatestWith = internal.zipLatestWith;
/**
 * Zips this stream with another point-wise, but keeps only the outputs of
 * this stream.
 *
 * The new stream will end when one of the sides ends.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipLatestWith = zipLatestWith;
const zipLeft = internal.zipLeft;
/**
 * Zips this stream with another point-wise, but keeps only the outputs of the
 * other stream.
 *
 * The new stream will end when one of the sides ends.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipLeft = zipLeft;
const zipRight = internal.zipRight;
/**
 * Zips this stream with another point-wise and applies the function to the
 * paired elements.
 *
 * The new stream will end when one of the sides ends.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipRight = zipRight;
const zipWith = internal.zipWith;
/**
 * Zips this stream with another point-wise and applies the function to the
 * paired elements.
 *
 * The new stream will end when one of the sides ends.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipWith = zipWith;
const zipWithChunks = internal.zipWithChunks;
/**
 * Zips each element with the next element if present.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipWithChunks = zipWithChunks;
const zipWithNext = internal.zipWithNext;
/**
 * Zips each element with the previous element. Initially accompanied by
 * `None`.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipWithNext = zipWithNext;
const zipWithPrevious = internal.zipWithPrevious;
/**
 * Zips each element with both the previous and next element.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipWithPrevious = zipWithPrevious;
const zipWithPreviousAndNext = internal.zipWithPreviousAndNext;
/**
 * Zips this stream together with the index of elements.
 *
 * @since 1.0.0
 * @category zipping
 */
exports.zipWithPreviousAndNext = zipWithPreviousAndNext;
const zipWithIndex = internal.zipWithIndex;
/**
 * @category instances
 * @since 1.0.0
 */
exports.zipWithIndex = zipWithIndex;
const Bicovariant = {
  bimap: mapBoth
};
exports.Bicovariant = Bicovariant;
const imap = /*#__PURE__*/covariant.imap(map);
/**
 * @category instances
 * @since 1.0.0
 */
const Covariant = {
  imap,
  map
};
/**
 * @category instances
 * @since 1.0.0
 */
exports.Covariant = Covariant;
const Invariant = {
  imap
};
/**
 * @category instances
 * @since 1.0.0
 */
exports.Invariant = Invariant;
const Pointed = {
  of: succeed,
  imap,
  map
};
/**
 * @category instances
 * @since 1.0.0
 */
exports.Pointed = Pointed;
const FlatMap = {
  flatMap
};
/**
 * @category instances
 * @since 1.0.0
 */
exports.FlatMap = FlatMap;
const Chainable = {
  imap,
  map,
  flatMap
};
/**
 * @category instances
 * @since 1.0.0
 */
exports.Chainable = Chainable;
const Monad = {
  imap,
  of: succeed,
  map,
  flatMap
};
/**
 * @category do notation
 * @since 1.0.0
 */
exports.Monad = Monad;
const Do = /*#__PURE__*/of_.Do(Pointed);
/**
 * @category do notation
 * @since 1.0.0
 */
exports.Do = Do;
const bind = /*#__PURE__*/chainable.bind(Chainable);
/**
 * @category do notation
 * @since 1.0.0
 */
exports.bind = bind;
const bindDiscard = /*#__PURE__*/(0, _Function.dual)(3, (self, name, f) => bind(self, name, () => f));
exports.bindDiscard = bindDiscard;
const let_ = /*#__PURE__*/covariant.let(Covariant);
exports.let = let_;
/**
 * @category do notation
 * @since 1.0.0
 */
const letDiscard = /*#__PURE__*/covariant.letDiscard(Covariant);
exports.letDiscard = letDiscard;
//# sourceMappingURL=Stream.js.map